# ROBERTA MODEL
[Kaggle : jigsaw-multilingual-toxic-comment-classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification/data) 
---
- コメントが有毒なコメントである確率を予測する。有毒なコメントは1.0。良性で毒性のないコメントは0.0。
- このNotebookを実行した場合のKaggleでのScoreは0.9306。
- TPUの使用状況の関係から、Fine_Tuningなどの詳細な設定は行っていない。
---
現在の最先端モデル
- [RoBERTa](https://arxiv.org/abs/1907.11692)
- [ALBERT](https://arxiv.org/abs/1909.11942)
- [GPT-2](https://github.com/openai/gpt-2)
- [XLNet](https://arxiv.org/abs/1906.08237)
- [T5](https://arxiv.org/abs/1910.10683),[ERNIE](https://github.com/PaddlePaddle/ERNIE)
- [MT-DNN](https://github.com/namisan/mt-dnn)
